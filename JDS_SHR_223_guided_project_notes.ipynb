{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vasanta2002/sprint_6/blob/main/JDS_SHR_223_guided_project_notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUhphDysw-6P"
      },
      "source": [
        "## BloomTech Data Science\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvWhcow-dvS8"
      },
      "source": [
        "# Cross-Validation\n",
        "\n",
        "- Do **k-fold cross-validation** with independent test set\n",
        "- Use scikit-learn for **hyperparameter optimization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRgkCSgGdty-"
      },
      "source": [
        "%%capture\n",
        "!pip install category_encoders==2.*"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HF70Jp0x4NJU"
      },
      "source": [
        "from category_encoders import OrdinalEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import cross_val_score, validation_curve # k-fold CV\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV # Hyperparameter tuning\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVzQtNC9oucF"
      },
      "source": [
        "# Downloading the Tanzania Waterpump Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-olXlnJoucR"
      },
      "source": [
        "Make sure  you only use the dataset that is available through the **DS** **Kaggle Competition**. DO NOT USE any other Tanzania waterpump datasets that you might find online.\n",
        "\n",
        "There are two ways you can get the dataset. Make sure you have joined the competition first!:\n",
        "\n",
        "1. You can download the dataset directly by accessing the challenge and the files through the Kaggle Competition URL on Canvas (make sure you have joined the competition!)\n",
        "\n",
        "2. Use the Kaggle API using the code in the following cells. This article provides helpful information on how to fetch your Kaggle Dataset into Google Colab using the Kaggle API. \n",
        "\n",
        "> https://medium.com/analytics-vidhya/how-to-fetch-kaggle-datasets-into-google-colab-ea682569851a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6TZ5nDFYkCa"
      },
      "source": [
        "# Using Kaggle API to download datset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2e6fPUATxLZ",
        "outputId": "237133ab-13eb-426e-f043-7dad769725ce"
      },
      "source": [
        "# mounting your google drive on colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYSpUv9uYBAo",
        "outputId": "87863757-937d-418e-fb56-d5f08e828ba2"
      },
      "source": [
        "#change your working directory, if you want to or have already saved your kaggle dataset on google drive.\n",
        "%cd /content/gdrive/My Drive/Kaggle\n",
        "# update it to your folder location on drive that contians the dataset and/or kaggle API token json file."
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/Kaggle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXChvgdZYb_t"
      },
      "source": [
        "# Download your Kaggle Dataset, if you haven't already done so. \n",
        "# import os\n",
        "# os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\"\n",
        "# !kaggle competitions download -c bloomtech-water-pump-challenge"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NB84qgRRYdDF"
      },
      "source": [
        "# Unzip your Kaggle dataset, if you haven't already done so.\n",
        "# !unzip \\*.zip  && rm *.zip"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eag2zYiQYf6q",
        "outputId": "eabdd0af-82f3-4b24-d98c-110793c619e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# List all files in your Kaggle folder on your google drive.\n",
        "!ls"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bloomtech-water-pump-challenge.zip  sample_submission.csv  train_labels.csv\n",
            "kaggle.json\t\t\t    test_features.csv\n",
            "new_submission.csv\t\t    train_features.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCBYPw7kd1AN"
      },
      "source": [
        "# I. Wrangle Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaXMenXoZ0D6"
      },
      "source": [
        "def wrangle(fm_path, tv_path=None):\n",
        "  if tv_path:\n",
        "    df = pd.merge(pd.read_csv(fm_path, \n",
        "                              na_values=[0, -2.000000e-08],\n",
        "                              parse_dates=['date_recorded']),\n",
        "                  pd.read_csv(tv_path)).set_index('id')\n",
        "  else:\n",
        "    df = pd.read_csv(fm_path, \n",
        "                     na_values=[0, -2.000000e-08],\n",
        "                     parse_dates=['date_recorded'],\n",
        "                     index_col='id')\n",
        "\n",
        "  # Drop constant columns\n",
        "  df.drop(columns=['recorded_by'], inplace=True)\n",
        "\n",
        "  # Create age feature\n",
        "  df['pump_age'] = df['date_recorded'].dt.year - df['construction_year']\n",
        "  df.drop(columns='date_recorded', inplace=True)\n",
        "\n",
        "  # Drop HCCCs\n",
        "  cutoff = 100\n",
        "  drop_cols = [col for col in df.select_dtypes('object').columns\n",
        "              if df[col].nunique() > cutoff]\n",
        "  df.drop(columns=drop_cols, inplace=True)\n",
        "\n",
        "  # Drop duplicate columns\n",
        "  dupe_cols = [col for col in df.head(100).T.duplicated().index # change 15 to 100!!!!\n",
        "               if df.head(100).T.duplicated()[col]]\n",
        "  df.drop(columns=dupe_cols, inplace=True)             \n",
        "\n",
        "  return df\n",
        "\n",
        "df = wrangle(fm_path='train_features.csv',\n",
        "             tv_path='train_labels.csv')\n",
        "\n",
        "X_test = wrangle(fm_path='test_features.csv')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wupyZysm_avz",
        "outputId": "c282e11f-902b-4724-f5d1-059895d9eb97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df.shape, X_test.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((47519, 31), (11880, 30))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jetWccxMqmzY"
      },
      "source": [
        "# II. Split Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-MPA0qlr-mK"
      },
      "source": [
        "## Split TV from FM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target = 'status_group'\n",
        "y = df[target]\n",
        "X = df.drop(columns = target)"
      ],
      "metadata": {
        "id": "-iN01DozUbyH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WX9uvMMgs6J_"
      },
      "source": [
        "# III. Establish Baseline\n",
        "\n",
        "This is a **classification** problem, our baseline will be **accuracy**. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.value_counts(normalize = True).max()"
      ],
      "metadata": {
        "id": "PkUJVqSuULDg",
        "outputId": "e5abd5f6-4731-4cd8-aa8a-d9dfb64c0d40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5429828068772491"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MA19NsrFtgTT"
      },
      "source": [
        "# IV. Build Models\n",
        "\n",
        "- `DecisionTreeClassifier`\n",
        "- `RandomForestClassifier`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_ZpJSwObNl_"
      },
      "source": [
        "model_dt = make_pipeline(\n",
        "    OrdinalEncoder(),\n",
        "    SimpleImputer(),\n",
        "    DecisionTreeClassifier(random_state=42))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4fO6aXEbNiQ"
      },
      "source": [
        "model_rf = make_pipeline(\n",
        "    OrdinalEncoder(),\n",
        "    SimpleImputer(),\n",
        "    RandomForestClassifier(n_estimators =25, random_state=42)\n",
        ");"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.common import random_state\n",
        "#kfold_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "cv_scores_dt = cross_val_score(model_dt, X, y, cv=5, n_jobs=-1)\n",
        "cv_scores_rf = cross_val_score(model_rf, X, y, cv=5, n_jobs=-1)"
      ],
      "metadata": {
        "id": "JMQhiMQpEFwN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_scores_dt"
      ],
      "metadata": {
        "id": "c9Kku7czYPnI",
        "outputId": "91ffaeaa-3472-4721-bb86-7e5e7cc0c3ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.7444234 , 0.75126263, 0.74621212, 0.74863215, 0.7457645 ])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_scores_rf"
      ],
      "metadata": {
        "id": "OBQDOg8AYT-z",
        "outputId": "317d1b60-a482-4842-af0f-4652ada28320",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.79335017, 0.79692761, 0.79724327, 0.79892677, 0.79438072])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9S2e1zlmYYVx"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UQR0M1UyYYJ-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3PmkvF-8YXzt"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l96Atv4REyH3"
      },
      "source": [
        "**Check cross-validation scores**\n",
        "\n",
        "![Cross Validation](https://upload.wikimedia.org/wikipedia/commons/4/4b/KfoldCV.gif)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLx-EHNGB-xq",
        "outputId": "53965095-8f36-45ba-e800-8ad39e653e6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('CV score DecisionTreeClassifier')\n",
        "print('Mean CV accuracy score:', cv_scores_dt.mean() )\n",
        "print('STD CV accuracy score:', cv_scores_dt.std())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV score DecisionTreeClassifier\n",
            "Mean CV accuracy score: 0.7472589596905601\n",
            "STD CV accuracy score: 0.0024201115777066104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLIdbPJpCC_S",
        "outputId": "2b140316-78b6-497e-8c3a-dcbf46757aa0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('CV score RandomForestClassifier')\n",
        "print('Mean CV accuracy score:', cv_scores_rf.mean())\n",
        "print('STD CV accuracy score:', cv_scores_rf.std())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV score RandomForestClassifier\n",
            "Mean CV accuracy score: 0.7961657066650226\n",
            "STD CV accuracy score: 0.0020237843032747736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSTF3aOWo-5-"
      },
      "source": [
        "# V. Tune Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcYCO2Cj4ILg"
      },
      "source": [
        "Different hyperparameter values I want to try out :\n",
        "\n",
        "*   Simpleimputer - mean, median - 2 values\n",
        "*   max_depth - range(5,40,5) - 7 values\n",
        "*   n_estimators - range(25,125,25) - 4 values\n",
        "\n",
        "> Total combinations of these hyperparameters = 2 * 7 * 4 = 56\n",
        "\n",
        "Testing out the above hyperparameter combinations with 5-fold Cross Validation will need :\n",
        "\n",
        "> Total number of models to be fit = 2 * 7 * 4 * 5 = 280\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = make_pipeline(\n",
        "    OrdinalEncoder(),\n",
        "    SimpleImputer(),\n",
        "    RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        ")"
      ],
      "metadata": {
        "id": "LgK-doeJWMAE"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'simpleimputer__strategy' :['mean', 'medain'],\n",
        "    'randomforestclassifier__max_depth' :range(5,40,5),\n",
        "    'randomforestclassifier__n_estimators' :range(25,125,25)\n",
        "}"
      ],
      "metadata": {
        "id": "jrMYSoldWL7l"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modle_rf_gs = GridSearchCV(clf,\n",
        "             param_grid=param_grid,\n",
        "             n_jobs=-1,\n",
        "             cv=5,\n",
        "             verbose=1,\n",
        "             )\n",
        "modle_rf_gs.fit(X,y)"
      ],
      "metadata": {
        "id": "02mPoIfYKtZa",
        "outputId": "5a4adc94-3389-4f34-af03-592a1f9eead9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "140 fits failed out of a total of 280.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "140 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 390, in fit\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 348, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/base.py\", line 855, in fit_transform\n",
            "    return self.fit(X, y, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/impute/_base.py\", line 319, in fit\n",
            "    X = self._validate_input(X, in_fit=True)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/impute/_base.py\", line 244, in _validate_input\n",
            "    raise ValueError(\n",
            "ValueError: Can only use these strategies: ['mean', 'median', 'most_frequent', 'constant']  got strategy=medain\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.72310018        nan 0.72381568        nan 0.72432075        nan\n",
            " 0.72419448        nan 0.75597126        nan 0.75723394        nan\n",
            " 0.75731808        nan 0.75761271        nan 0.79267233        nan\n",
            " 0.79513449        nan 0.79511342        nan 0.79618666        nan\n",
            " 0.80003785        nan 0.80170031        nan 0.8022685         nan\n",
            " 0.80336279        nan 0.7974494         nan 0.80087958        nan\n",
            " 0.8016161         nan 0.80277355        nan 0.79580794        nan\n",
            " 0.79818597        nan 0.79925919        nan 0.80014304        nan\n",
            " 0.79416653        nan 0.79797552        nan 0.79942762        nan\n",
            " 0.80014306        nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[('ordinalencoder', OrdinalEncoder()),\n",
              "                                       ('simpleimputer', SimpleImputer()),\n",
              "                                       ('randomforestclassifier',\n",
              "                                        RandomForestClassifier(n_jobs=-1,\n",
              "                                                               random_state=42))]),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'randomforestclassifier__max_depth': range(5, 40, 5),\n",
              "                         'randomforestclassifier__n_estimators': range(25, 125, 25),\n",
              "                         'simpleimputer__strategy': ['mean', 'medain']},\n",
              "             verbose=1)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRL-I2ensgom"
      },
      "source": [
        "**`GridSearch`:** "
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f27tFQRMWARw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPvNOV6Cw1Zl"
      },
      "source": [
        "**`RandomizedSearchCV`:** "
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WFXI-drCV9LB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wT5O4MpOV4qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6P_b_2u1V9II"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdPydrAciFvW"
      },
      "source": [
        "# VI. Communicate Results\n",
        "\n",
        "**Showing Feature Importance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orrZCcWqj0Wu"
      },
      "source": [
        "Plot the feature importance for our `RandomForest` model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bestestimator = \n",
        "importances = bestestimator.named_steps['randomforestclassifier'].feature_importances_\n",
        "features = X.columns\n",
        "feat_imp = pd.Series(importances, index=features).sort_values()\n",
        "feat_imp.tail(10).plot(kind='barh')\n",
        "plt.xlabel('Reduction in Gini Impurity');"
      ],
      "metadata": {
        "id": "X3QZfcikWWW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIiBxuSrDPZU"
      },
      "source": [
        "# VII. Make Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbEIotkT8eUM"
      },
      "source": [
        "y_pred = model_rfrs.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFL1Zdi88f98"
      },
      "source": [
        "submission = pd.DataFrame({'status_group':y_pred}, index=X_test.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission"
      ],
      "metadata": {
        "id": "cNjXGaXEM9Po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvrFM81t9Fqv"
      },
      "source": [
        "pd.Timestamp.now().strftime('%Y-%m-%d_%H%M_')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sDIlJ1fDPZW"
      },
      "source": [
        "datestamp = pd.Timestamp.now().strftime('%Y-%m-%d_%H%M_') #string from time format\n",
        "submission.to_csv(f'{datestamp}submission.csv') #format string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SS6EDRbCbr-F"
      },
      "source": [
        "# VIII. Saving a trained model to reuse it in the future"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Once you have found the best model, you might as well save it and then reload it when you want to test it later\n",
        "\n",
        "# save model\n",
        "import pickle\n",
        "\n",
        "filename = \n",
        "\n",
        "#save your model (it will be stored in your current working directory - download to your computer if GDrive is not mounted)\n",
        "pickle.dump(model_rf,open(filename,'wb'))\n",
        "#load model\n",
        "model_rf_loaded = pickle.load(open(filename,'rb'))"
      ],
      "metadata": {
        "id": "T1H0NSTQUh-A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}